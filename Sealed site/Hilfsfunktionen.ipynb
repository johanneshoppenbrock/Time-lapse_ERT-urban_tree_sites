{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4339cc3e-72a6-40df-8708-d8f825cbf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pygimli as pg\n",
    "import inspect\n",
    "from pygimli.physics import ert\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from datetime import datetime \n",
    "from influxdb_client import InfluxDBClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382f5671-ec95-4b36-9aa3-1a700e6f9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_function_FTL (data, manager, results, folder_name, filename, chi2, scalef, rrms):\n",
    "    fig, axs = plt.subplots(nrows=len(data), ncols=2, figsize=(10, len(data)*2.5))\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    axnr = -1\n",
    "    axs[0, 1].axis('off')\n",
    "    modell = results\n",
    "    name = folder_name\n",
    "    test = True \n",
    "    for counter, (d, res) in enumerate(zip(data, modell)):\n",
    "        # Resistivity image\n",
    "        axnr = axnr +1\n",
    "        row_index = counter*2\n",
    "        datum = datetime.strptime(d[0], '%y%m%d')\n",
    "        bild1 = manager[0].showResult(model = res, coverage = manager[0].coverage(),\n",
    "                cMin=10, cMax=300, logScale=True, cMap= 'jet', ax=axs[axnr, 0], label = 'Resistivity in $\\Omega$m')\n",
    "        axs[axnr, 0].set_title('Date: '+ str(datum.day) + '.' + str(datum.month) + '.' + str(datum.year))\n",
    "        if axnr < len(axs)-1:\n",
    "            cb = bild1[-1]\n",
    "            cb.remove()\n",
    "    \n",
    "        # Ratio image\n",
    "        if res[10] != modell[0][10]: \n",
    "            ratio = res / modell[counter-1]\n",
    "            bild2 = manager[0].showResult(model= ratio,coverage = manager[0].coverage(),\n",
    "                    cMin=1/2, cMax=2, cMap= 'bwr', ax= axs[axnr, 1], label = 'Change of resistivity', logScale= True)\n",
    "            if axnr < len(axs)-1:\n",
    "                cb = bild2[-1]\n",
    "                cb.remove() \n",
    "            axs[axnr, 1].set_title('$\\chi^2$: '+ str(chi2[0]) + '; rrms: '+ str(rrms[0])+ ' %',  loc = 'right')\n",
    "            axs[axnr, 1].set_title('SF: '+ str(scalef), loc = 'left')\n",
    "            tree_postions = [7, 16.5, 28, 37, 47]\n",
    "            for x in tree_postions:\n",
    "                axs[axnr, 1].plot(x, 0, '.', markersize=10, color='black')\n",
    "            axs[axnr, 1].set_ylim(-15, 0) \n",
    "            axs[axnr, 0].set_ylim(-15, 0)\n",
    "            axs[axnr, 1].axhline(y=-4.5, color='k', linewidth = 1,linestyle='--')\n",
    "    for ax in axs:\n",
    "        ax[0].set_xlabel('Distance (m)')\n",
    "        ax[0].set_ylabel('Depth (m)')\n",
    "        ax[1].set_xlabel('Distance (m)')\n",
    "        ax[1].set_ylabel('Depth (m)')\n",
    "    \n",
    "    isExist = os.path.exists('./Inversion_results/' + '/%s_inversion' % name)\n",
    "    if not isExist:\n",
    "        os.makedirs('./Inversion_results/' + '/%s_inversion' % name)\n",
    "    fig.savefig('./Inversion_results/' + '/%s_inversion' '/%s.png' % (name, filename), bbox_inches = 'tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f38d535-a36b-4cd7-a9fd-fd582fa03c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_function (data, manager, results, folder_name, filename, chi2, lam):\n",
    "    fig, axs = plt.subplots(nrows=len(data), ncols=2, figsize=(10, len(data)*2.5))\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    axnr = -1\n",
    "    axs[0, 1].axis('off')\n",
    "    modell = results\n",
    "    name = folder_name\n",
    "    for counter, (d, res) in enumerate(zip(data, modell)):\n",
    "        # Resistivity image\n",
    "        axnr = axnr +1\n",
    "        row_index = counter*2\n",
    "        datum = datetime.strptime(d[0], '%y%m%d')\n",
    "        bild1 = manager[0].showResult(model = res, coverage = manager[0].coverage(),\n",
    "                cMin=10, cMax=300, logScale=True, cMap= 'jet', ax=axs[axnr, 0], label = 'Resistivity in $\\Omega$m')\n",
    "        axs[axnr, 0].set_title('Date: '+ str(datum.day) + '.' + str(datum.month) + '.' + str(datum.year))\n",
    "        if axnr < len(axs)-1:\n",
    "            cb = bild1[-1]\n",
    "            cb.remove()\n",
    "    \n",
    "        # Ratio image\n",
    "        if res[10] != modell[0][10]: \n",
    "            ratio = res / modell[counter-1]\n",
    "            bild2 = manager[0].showResult(model= ratio,coverage = manager[0].coverage(),\n",
    "                    cMin=1/2, cMax=2, cMap= 'bwr', ax= axs[axnr, 1], label = 'Change of resistivity', logScale= True)\n",
    "            if axnr < len(axs)-1:\n",
    "                cb = bild2[-1]\n",
    "                cb.remove() \n",
    "            axs[axnr, 1].set_title('$\\chi^2$ - 1: '+ str(chi2[counter-1]) + '; $\\chi^2$ - 2: ' + str(chi2[counter]), loc = 'right')\n",
    "            axs[axnr, 1].set_title('$\\lambda = $'+ str(lam), loc = 'left')\n",
    "            tree_postions = [7, 16.5, 28, 37, 47]\n",
    "            for x in tree_postions:\n",
    "                axs[axnr, 1].plot(x, 0, '.', markersize=10, color='black')\n",
    "            axs[axnr, 1].set_ylim(-15, 0) \n",
    "            axs[axnr, 0].set_ylim(-15, 0)\n",
    "            axs[axnr, 1].axhline(y=-4.5, color='k', linewidth = 1,linestyle='--')\n",
    "    for ax in axs:\n",
    "        ax[0].set_xlabel('Distance (m)')\n",
    "        ax[0].set_ylabel('Depth (m)')\n",
    "        ax[1].set_xlabel('Distance (m)')\n",
    "        ax[1].set_ylabel('Depth (m)')\n",
    "    \n",
    "    isExist = os.path.exists('./Inversion_results/' + '/%s_inversion' % name)\n",
    "    if not isExist:\n",
    "        os.makedirs('./Inversion_results/' + '/%s_inversion' % name)\n",
    "    fig.savefig('./Inversion_results/' + '/%s_inversion' '/%s.png' % (name, filename), bbox_inches = 'tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1501899e-d599-4cb0-9345-4c67937ef9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    wenner = []\n",
    "    dd = []\n",
    "    dataset = filename\n",
    "    date = os.listdir(\"./Data/\" + dataset)\n",
    "    globals()['%s_wenner' % (dataset)] = [] # definiere Max_Osterloh_Platz_Wenner\n",
    "    globals()['%s_datum' % (dataset)] = [] # definiere Max_Osterloh_Platz_datum\n",
    "    globals()['%s_dd' % (dataset)]= [] # definiere Max_Osterloh_Platz_dd\n",
    "    wenner = []\n",
    "    dd = []\n",
    "    for datum in date:\n",
    "        dateien = os.listdir(\"./Data/\" + dataset +'/'+ datum) # Dateien im Ordner des Datums einlesen\n",
    "        globals()['%s_datum' % (dataset)].append(datum) # Datum zu Max_Osterloh_Platz_datum hinzufügen\n",
    "        for datei in dateien: \n",
    "            if (datei).startswith('Wen'):\n",
    "                wenner.append([datum, pg.load(\"./Data/\" + dataset +'/'+ datum+'/'+datei)])\n",
    "            if (datei).startswith('Dip'):\n",
    "                dd.append([datum, pg.load(\"./Data/\" + dataset +'/'+ datum+'/'+datei)])\n",
    "    return wenner, dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a63d67-e916-4873-88a3-1ee761c5244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misfit_correction(wenner, inv, maximum_error): \n",
    "    \"\"\"Filtering with respect to misfit  \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wenner: Wenner dataset  \n",
    "    inv: inversion instance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    copy_misfit_corrected: copy of corrected data \n",
    "    \"\"\"\n",
    "    \n",
    "    start = 0 \n",
    "    for wen in wenner:\n",
    "        misfit = - inv.response[start:(start+len(wen[1]['rhoa']))] / wen[1][\"rhoa\"] * 100 + 100\n",
    "        print(misfit)\n",
    "        manager[0].showData(misfit, cMap = 'bwr', cMin= -50, cMax = 50)\n",
    "        start = start + len(wen[1]['rhoa'])\n",
    "        \n",
    "        for count,mis in enumerate(misfit):\n",
    "            if mis > maximum_error:\n",
    "                wen[1].markInvalid(count)\n",
    "    for we in wenner: \n",
    "        we[1].removeInvalid()\n",
    "    return wenner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75facd17-94ff-4e28-80cc-406a8b32423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_corr_nach_Inversion(resistivity, mesh, Temp_tiefe_vektor):\n",
    "    res_new = resistivity.copy()\n",
    "    Tem_new = resistivity.copy()\n",
    "    # Mesh nur mit Inversionsregion\n",
    "    for count, (res, loc) in enumerate(zip(resistivity, mesh.cellCenter())) :\n",
    "        #print(loc[1])\n",
    "        if loc[1] > Temp_tiefe_vektor[0][0]:\n",
    "            T = Temp_tiefe_vektor[0][1]\n",
    "        else:\n",
    "            for tiefe in Temp_tiefe_vektor:\n",
    "                if  tiefe[0] + 0.025 > loc[1] > tiefe[0] - 0.025:\n",
    "                    T = tiefe[1]\n",
    "                    break\n",
    "                else:\n",
    "                    T = 10\n",
    "         \n",
    "        Tem_new[count] = T\n",
    "        res_new[count] = (1 + 0.025 *(T-25))*res # temperature correction\n",
    "    return res_new,Tem_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85a0b5f2-e8d4-4f37-aa06-1e232ef3ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust(data_list):\n",
    "# reduziert Daten auf kleinstes Glied\n",
    "    for k in [0,1]:\n",
    "        for nummer in range(len(data_list)):\n",
    "            data_timestep1 = data_list[nummer][1]\n",
    "            if nummer == len(data_list)-1:\n",
    "                data_timestep2 = data_list[0][1]\n",
    "            else:\n",
    "                data_timestep2 = data_list[nummer+1][1]\n",
    "            #print(data_timestep1)\n",
    "            for nr, a2,b2,m2,n2 in zip(range(len(data_timestep2['a'])),data_timestep2['a'], data_timestep2['b'],data_timestep2['m'], data_timestep2['n']):\n",
    "                boolean = False \n",
    "                #print(nr)\n",
    "                for a1,b1,m1,n1 in zip(data_timestep1['a'], data_timestep1['b'],data_timestep1['m'], data_timestep1['n']):\n",
    "                    if a1==a2 and b2==b1 and m2==m1 and n2==n1:\n",
    "                        boolean = True \n",
    "                if boolean == False:\n",
    "                    #print(nr)\n",
    "                    data_timestep2['valid'][nr]= 0 \n",
    "            data_timestep2.removeInvalid()\n",
    "            data_timestep1.removeInvalid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f13ea957-f2df-4615-8dfd-a11d92ee592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(data, max_err, smallest_rhoa, biggest_rhoa, err_abs, err_rel, max_err_est, parameter = 'rhoa', setError=False, sort_out_error = 1):\n",
    "    # Geometriefaktor berechnen\n",
    "    data['k'] =ert.createGeometricFactors(data, numerical=True)\n",
    "    # Bulk resistivity\n",
    "    data['r'] = data[parameter]/data['k']\n",
    "    # Filtering\n",
    "    \n",
    "    if setError: # Wenn Fehler hochgesetzt werden sollen \n",
    "        # Großen Fehlern einen noch größeren Fehler geben \n",
    "        err_index_list = []\n",
    "        for nr, err in zip(range(len(data['rhoa']) - 1, -1, -1), reversed(data['err'])):\n",
    "            if err*100 > max_err:\n",
    "                err_index_list.append(nr)\n",
    "        \n",
    "        data['err'] = ert.estimateError(data, \n",
    "                            absoluteError=err_abs, \n",
    "                            relativeError=err_rel)\n",
    "        for index in err_index_list:\n",
    "            data['err'][index]= sort_out_error\n",
    "    \n",
    "    \n",
    "\n",
    "        for nr, rhoa, err in zip(range(len(data['rhoa'])-1, -1 ,-1),reversed(data['rhoa']), reversed(data['err'])):\n",
    "            if rhoa > biggest_rhoa or rhoa < smallest_rhoa:\n",
    "                data['err'][nr]= sort_out_error\n",
    "            if err*100 > max_err:\n",
    "                data['err'][nr]= sort_out_error\n",
    "    else:\n",
    "        \n",
    "        data.markInvalid(data['err']*100 > max_err)\n",
    "        data.markInvalid(data[parameter] < smallest_rhoa)\n",
    "        data.markInvalid(data[parameter] > biggest_rhoa)\n",
    "        data['err'] = ert.estimateError(data, \n",
    "                    absoluteError=err_abs, \n",
    "                    relativeError=err_rel)\n",
    "        \n",
    "        data.markInvalid(data['err']*100 > max_err_est)\n",
    "\n",
    "        \n",
    "       #data.remove(data['err']*100 > max_err)\n",
    "       #data.remove(data[parameter] < smallest_rhoa)\n",
    "       #data.remove(data[parameter] > biggest_rhoa)\n",
    "       #data['err'] = ert.estimateError(data, \n",
    "       #            absoluteError=err_abs, \n",
    "       #            relativeError=err_rel)\n",
    "       #\n",
    "       #data.remove(data['err']*100 > max_err_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517e200f-1638-4cdb-ae5f-b2cd77f51e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def einlesen_ip(filename):\n",
    "    wenner = []\n",
    "    dd = []\n",
    "    ort = filename\n",
    "    date = os.listdir(\"./Messdaten_ip/\" + ort)\n",
    "    print(date)\n",
    "    globals()['%s_wenner' % (ort)] = [] # definiere Max_Osterloh_Platz_Wenner\n",
    "    globals()['%s_datum' % (ort)] = [] # definiere Max_Osterloh_Platz_datum\n",
    "    globals()['%s_dd' % (ort)]= [] # definiere Max_Osterloh_Platz_dd\n",
    "    wenner = []\n",
    "    dd = []\n",
    "    for datum in date:\n",
    "        dateien = os.listdir(\"./Messdaten_ip/\" + ort +'/'+ datum) # Dateien im Ordner des Datums einlesen\n",
    "        globals()['%s_datum' % (ort)].append(datum) # Datum zu Max_Osterloh_Platz_datum hinzufügen\n",
    "        for datei in dateien: \n",
    "            if (datei).startswith('Wen'):\n",
    "                wenner.append([datum, pg.load(\"./Messdaten_ip/\" + ort +'/'+ datum+'/'+datei)])\n",
    "            if (datei).startswith('Dip'):\n",
    "                dd.append([datum, pg.load(\"./Messdaten_ip/\" + ort +'/'+ datum+'/'+datei)])\n",
    "    print('Schreibe zwei Listen (Wen, Dip) mit den jeweiligen Daten dazu.')\n",
    "    return wenner, dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8bf85f5-da20-4429-a9ca-48f669463921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def einlesen_tagesgang(filename, date):\n",
    "    wenner = []\n",
    "    dd = []\n",
    "    ort = filename\n",
    "    globals()['%s_wenner' % (ort)] = [] # definiere Max_Osterloh_Platz_Wenner\n",
    "    globals()['%s_datum' % (ort)] = [] # definiere Max_Osterloh_Platz_datum\n",
    "    globals()['%s_dd' % (ort)]= [] # definiere Max_Osterloh_Platz_dd\n",
    "    wenner = []\n",
    "    dd = []\n",
    "    uhrzeiten = os.listdir(\"./Messdaten_pg/\" + ort +'/'+ date)\n",
    "    for zeit in uhrzeiten:\n",
    "        if zeit[0].isdigit():\n",
    "            print('Uhrzeit: ' +zeit)\n",
    "            dateien = os.listdir(\"./Messdaten_pg/\" + ort +'/'+ date + '/' + zeit) # Dateien im Ordner des Datums einlesen\n",
    "            globals()['%s_datum' % (ort)].append(zeit) # Datum zu Max_Osterloh_Platz_datum hinzufügen\n",
    "            for datei in dateien: \n",
    "                if (datei).startswith('Wen'):\n",
    "                    wenner.append([date+zeit, pg.load(\"./Messdaten_pg/\" + ort +'/'+ date+'/'+ zeit +'/'+datei)])\n",
    "                if (datei).startswith('Dip'):\n",
    "                    dd.append([date+zeit, pg.load(\"./Messdaten_pg/\" + ort +'/'+ date+'/'+ zeit +'/'+datei)])\n",
    "            print('Schreibe zwei Listen (Wen, Dip) mit den jeweiligen Daten dazu.')\n",
    "    return wenner, dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881827be-bc7d-418e-87b9-c85ff28e45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zuordnung(wenner, dd):\n",
    "    for dipol in dd:\n",
    "        for wen in wenner: \n",
    "            if dipol[0] == wen[0]:\n",
    "                wen[1].add(dipol[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107e6fcf-eac4-425d-b12a-f1a0e79ac31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es werden Werte aussortiert bei denen für beide benachbarten Punkte gilt, dass rho_diff/rho > filter_value\n",
    "#filter_value = 1 #Abstand/Wert\n",
    "#data = wenner[3][1]\n",
    "\n",
    "def filter(data, parameter = 'rhoa', filter_value = 1, setError = False, sort_out_error = 1):\n",
    "# Filter Stärker, wenn filter_value kleiner\n",
    "    for ind in range(len(data['a'])):\n",
    "        #print(ind)\n",
    "        if 0 < ind < len(data['a'])-1 and abs(data['a'][ind] - data['a'][ind-1]) < 5 and abs(data['a'][ind] - data['a'][ind+1]) < 5 :\n",
    "            #print('jetzt: ' + str(data['a'][ind]))\n",
    "            #print('vorheriger Wert: ' + str(data[parameter][ind-1]) + ' jetziger Wert: ' + str(data[parameter][ind]) + ' DIfferenz: ' + str(abs(data[parameter][ind] -  data[parameter][ind-1])) )\n",
    "            if ((abs(data[parameter][ind] -  data[parameter][ind-1]) / data[parameter][ind] > filter_value and \n",
    "                 abs(data[parameter][ind] -  data[parameter][ind+1])/data[parameter][ind] > filter_value) or \n",
    "                (abs(data[parameter][ind] -  data[parameter][ind+1])/data[parameter][ind+1] > filter_value and\n",
    "                 abs(data[parameter][ind] -  data[parameter][ind-1])/data[parameter][ind-1] > filter_value)):\n",
    "                \n",
    "                #print('pick')\n",
    "                if setError == True:\n",
    "                    data['err'][ind]= sort_out_error\n",
    "                else:\n",
    "                    data.markInvalid(ind)\n",
    "    for ind in range(len(data['a'])):\n",
    "        if 0 < ind < len(data['a'])-1 and 0 < ind < len(data['a'])-1 and abs(data['a'][ind] - data['a'][ind-1]) > 5 :\n",
    "            # Anfang Reihexyvc fe\n",
    "            if abs(data[parameter][ind] -  data[parameter][ind+1])/data[parameter][ind] > filter_value:\n",
    "                if setError == True:\n",
    "                    data['err'][ind]= sort_out_error\n",
    "                else:\n",
    "                    data.markInvalid(ind)\n",
    "\n",
    "        if 0 < ind < len(data['a'])-1 and 0 < ind < len(data['a'])-1 and abs(data['a'][ind] - data['a'][ind+1]) > 5: \n",
    "            # Ende Reihe \n",
    "            if abs(data[parameter][ind] -  data[parameter][ind-1])/data[parameter][ind] > filter_value:\n",
    "                if setError == True:\n",
    "                    data['err'][ind]= sort_out_error          \n",
    "                \n",
    "                else:\n",
    "                    data.markInvalid(ind)\n",
    "    \n",
    "    #data.removeInvalid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4390fe3-cc35-49d8-8bce-a09d534d9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gefilterte Daten abspeichern\n",
    "def save_filtered_data(folder_new, ort, wenner, dd):\n",
    "    datum = 0 \n",
    "    for wenner2 in wenner:\n",
    "        if datum is not wenner2[0]:\n",
    "            nummer = 1\n",
    "        else:\n",
    "            nummer = nummer + 1 \n",
    "            \n",
    "        datum = wenner2[0]\n",
    "        isExist = os.path.exists(folder_new + '/' + ort +'/'+ datum)\n",
    "        if not isExist:\n",
    "           # Create a new directory because it does not exist\n",
    "            os.makedirs(folder_new + '/' + ort +'/'+ datum)\n",
    "            print(\"The new directory is created!\")\n",
    "        [wenner2[1].save(folder_new + '/' + ort +'/'+ datum+'/Wenner%s.ohm' % str(nummer))]\n",
    "    datum = 0 \n",
    "    for dd2 in dd:\n",
    "        if datum is not dd2[0]:\n",
    "            nummer = 1\n",
    "        else:\n",
    "            nummer = nummer + 1 \n",
    "            \n",
    "        datum = dd2[0]\n",
    "        [dd2[1].save(folder_new + '/' + ort +'/'+ datum+'/DipDip%s.ohm' % str(nummer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98fe675a-da90-4e2b-8713-29910c402ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resistivity_area(mesh, mod, x_min, x_max, y_min, y_max):\n",
    "    \"\"\"Widerstände in definiertem Bereich und Median der Widerstände\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_min: x-Minimum of area of interest \n",
    "    x_max: x-Maximum of area of interest \n",
    "    y_min: y-Minimum of area of interest (e.g. -0.75)\n",
    "    y_max: y-Maximum of area of interest (e.g. -0.25)\n",
    "    mod: Liste der Inversionsergebnisse \n",
    "    mesh: Mesh, das zum Datensatz passt\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tiefenverlauf : Für jeden Zeitschritt Liste von Widerständen im Bereich. \n",
    "    \"\"\"\n",
    "    tiefenverlauf = []\n",
    "    cell_centers = np.array([cell.center() for cell in mesh.cells()])\n",
    "    mask = (cell_centers[:,0] > x_min) & (cell_centers[:,0] < x_max) & (cell_centers[:,1] > y_min) & (cell_centers[:,1] < y_max)\n",
    "    area = cell_centers[mask]\n",
    "    for count, m in enumerate(mod): \n",
    "        para = pg.Mesh(mesh)  # make a copy\n",
    "        para.setCellMarkers(pg.IVector(para.cellCount()))\n",
    "        fopDP = pg.frameworks.PriorModelling(para, area)\n",
    "        tiefenverlauf.append(fopDP(m))\n",
    "    return tiefenverlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f5813d9-4a9c-4855-aa0f-dc4f5e0e768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sensor_data(standort, wenner, Uhrzeit_start, Uhrzeit_ende, list_of_depth):\n",
    "    \"\"\"Feuchtesensordaten auslesen und in Dataframes ausgeben\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    standort: Standort der vermessen wurde \n",
    "    wenner: Zeitreihe mit Daten \n",
    "    Uhrzeit_start, Uhrzeit_ende: Zeitraum in dem nach Feuchtesensordaten gesucht wird, meist 1h \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_frame_TDR_list : Liste mit Dataframes für jede Tiefe.\n",
    "    \"\"\"\n",
    "    start_date = []\n",
    "    end_date = []\n",
    "    ticks = []\n",
    "    data_frame_list = []\n",
    "    datum = [eintrags_tuple[0] for eintrags_tuple in wenner]\n",
    "    for tag in datum: \n",
    "        start_date.append('%sT%s:00:00Z' % (str((datetime.strptime(tag, '%y%m%d')).date()),Uhrzeit_start))\n",
    "        end_date.append('%sT%s:00:00Z' % (str((datetime.strptime(tag, '%y%m%d')).date()),Uhrzeit_ende))\n",
    "        ticks.append(str((datetime.strptime(tag, '%y%m%d')).date()))\n",
    "        \n",
    "    for i, depth in enumerate(list_of_depth):\n",
    "        data_frame = None\n",
    "        for start, end in zip(start_date, end_date):\n",
    "            if data_frame is None: \n",
    "                with InfluxDBClient(\n",
    "                    url=\"https://database.isodrones.de\",\n",
    "                    token=\"AWAE4XarwTdDkgePJp-hvLDqV-lKBuUYecVc4RFqYpddJxD_-ICSK8E_AUksqSJ6i5_qp8e_QHk9D5B4kxvs9Q==\",\n",
    "                    org=\"isodrones\",\n",
    "                    debug=False,\n",
    "                ) as client:\n",
    "                    query_api = client.query_api()\n",
    "                    data_frame = (query_api.query_data_frame('''\n",
    "                    from(bucket:\"climax2\") \n",
    "                        |> range(start: %s, stop: %s) \n",
    "                        |> filter(fn: (r) => r[\"location\"] == \"depth_cm_%s\")\n",
    "                        |> filter(fn: (r) => r[\"site\"] == \"%s\")\n",
    "                        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\") \n",
    "                    ''' % (start, end,str(depth), standort))) \n",
    "                if data_frame.empty:\n",
    "                    # Eine Zeile mit NaNs erzeugen\n",
    "                    data_frame = pd.DataFrame(\n",
    "                        [[np.nan]*len(data_frame.columns)],  # Liste mit NaN-Werten\n",
    "                        columns=data_frame.columns\n",
    "                    )  \n",
    "\n",
    "                continue\n",
    "                      \n",
    "            with InfluxDBClient(\n",
    "                url=\"https://database.isodrones.de\",\n",
    "                token=\"AWAE4XarwTdDkgePJp-hvLDqV-lKBuUYecVc4RFqYpddJxD_-ICSK8E_AUksqSJ6i5_qp8e_QHk9D5B4kxvs9Q==\",\n",
    "                org=\"isodrones\",\n",
    "                debug=False,\n",
    "            ) as client:\n",
    "                query_api = client.query_api()\n",
    "                zusatz = (query_api.query_data_frame('''\n",
    "                from(bucket:\"climax2\") \n",
    "                    |> range(start: %s, stop: %s) \n",
    "                    |> filter(fn: (r) => r[\"location\"] == \"depth_cm_%s\")\n",
    "                    |> filter(fn: (r) => r[\"site\"] == \"%s\")\n",
    "                    |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\") \n",
    "                ''' % (start, end,str(depth), standort)))\n",
    "            try:\n",
    "                # Versuch, die erste Zeile aus 'zusatz' anzuhängen\n",
    "                data_frame = pd.concat([data_frame, zusatz.iloc[[0]]], ignore_index=True)\n",
    "            except:\n",
    "                # Falls das schiefgeht (z.B. 'zusatz' ist leer oder Index uncached),\n",
    "                # füge stattdessen eine Zeile mit NaN hinzu\n",
    "                nan_row = pd.DataFrame([[np.nan]*len(data_frame.columns)], columns=data_frame.columns)\n",
    "                data_frame = pd.concat([data_frame, nan_row], ignore_index=True)\n",
    "\n",
    "    \n",
    "        data_frame_list.append(data_frame)\n",
    "    data_frame_TDR_list = []\n",
    "    for data_frame in data_frame_list:\n",
    "        if 'BulkEC_mS/m' in data_frame.columns:\n",
    "            data_frame_TDR_list.append(data_frame[['_time', 'location', 'Temperature_°C', 'WaterContent_%vol','BulkEC_mS/m']].copy())\n",
    "            continue\n",
    "        data_frame_TDR_list.append(data_frame[['_time', 'location', 'Temperature_°C', 'WaterContent_%vol']].copy())\n",
    "    return data_frame_TDR_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03def260-166a-468a-8615-6e3aa642c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sensor_data_continuous(standort, wenner, Uhrzeit_start, Uhrzeit_ende, list_of_depth):\n",
    "    \"\"\"Feuchtesensordaten auslesen und in Dataframes ausgeben\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    standort: Standort der vermessen wurde \n",
    "    wenner: Zeitreihe mit Daten \n",
    "    Uhrzeit_start, Uhrzeit_ende: Zeitraum in dem nach Feuchtesensordaten gesucht wird, meist 1h \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_frame_TDR_list : Liste mit Dataframes für jede Tiefe.\n",
    "    \"\"\"\n",
    "    start_date_strs = []\n",
    "    end_date_strs = []\n",
    "    datum = [eintrags_tuple[0] for eintrags_tuple in wenner]\n",
    "\n",
    "    # Berechne den frühesten Start und den spätesten Endzeitpunkt\n",
    "    earliest_start = min(datum)\n",
    "    latest_end = max(datum)\n",
    "    \n",
    "    # Formatiere die Start- und Endzeitpunkte\n",
    "    start_date_str = '%sT%s:00:00Z' % (str((datetime.strptime(earliest_start, '%y%m%d')).date()), Uhrzeit_start)\n",
    "    end_date_str = '%sT%s:00:00Z' % (str((datetime.strptime(latest_end, '%y%m%d')).date()), Uhrzeit_ende)\n",
    "    \n",
    "    data_frame_list = []\n",
    "    \n",
    "    for depth in list_of_depth:\n",
    "        with InfluxDBClient(\n",
    "            url=\"https://database.isodrones.de\",\n",
    "            token=\"AWAE4XarwTdDkgePJp-hvLDqV-lKBuUYecVc4RFqYpddJxD_-ICSK8E_AUksqSJ6i5_qp8e_QHk9D5B4kxvs9Q==\",\n",
    "            org=\"isodrones\",\n",
    "            debug=False,\n",
    "        ) as client:\n",
    "            query_api = client.query_api()\n",
    "            data_frame = query_api.query_data_frame('''\n",
    "            from(bucket:\"climax2\") \n",
    "                |> range(start: %s, stop: %s) \n",
    "                |> filter(fn: (r) => r[\"location\"] == \"depth_cm_%s\")\n",
    "                |> filter(fn: (r) => r[\"site\"] == \"%s\")\n",
    "                |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\") \n",
    "            ''' % (start_date_str, end_date_str,str(depth), standort)) \n",
    "    \n",
    "        data_frame_list.append(data_frame)\n",
    "    \n",
    "    data_frame_TDR_list = []\n",
    "    for data_frame in data_frame_list:\n",
    "        if 'BulkEC_mS/m' in data_frame.columns:\n",
    "            data_frame_TDR_list.append(data_frame[['_time', 'location', 'Temperature_°C', 'WaterContent_%vol','BulkEC_mS/m']].copy())\n",
    "        else:\n",
    "            data_frame_TDR_list.append(data_frame[['_time', 'location', 'Temperature_°C', 'WaterContent_%vol']].copy())\n",
    "    \n",
    "    return data_frame_TDR_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e5ecf9-be40-4e91-8860-b13479a5937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baumstandorte(Ort):\n",
    "    if Ort == 'Prinzenpark':\n",
    "        Baumkoordinaten = [1.5, 10.5, 17.5, 26.5, 34, 43]\n",
    "        return Baumkoordinaten\n",
    "    if Ort == 'Fontanestrasse':\n",
    "        Baumkoordinaten = [7.5,18,29.5,41]\n",
    "        return Baumkoordinaten\n",
    "    if Ort == 'Museumspark_neu':\n",
    "        Baumkoordinaten = [6.4, 11.2, 21]\n",
    "        return Baumkoordinaten\n",
    "    if Ort == 'Langer_Kamp':\n",
    "        Baumkoordinaten = [7,17.6,28.6,38.2,47.4]\n",
    "        return Baumkoordinaten\n",
    "    if Ort == 'Schillstrasse':\n",
    "        Baumkoordinaten = [1.0,13.3,25.5,37.5]\n",
    "        return Baumkoordinaten\n",
    "    if Ort == 'Georg_Westermann_Allee':\n",
    "        Baumkoordinaten = [2,10.5, 18.5, 32, 42]\n",
    "        return Baumkoordinaten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de87f9a3-238b-4643-9181-bd70d0a00ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feuchtesensoren(Ort):\n",
    "    if Ort == 'Fontanestrasse':\n",
    "        sensorpositionen = [9.8,9.8,9.8,9.8,9.8]\n",
    "        return sensorpositionen\n",
    "    if Ort == 'Museumspark_neu':\n",
    "        sensorpositionen = [7.8,7.8,7.8,7.8,7.8]\n",
    "        return sensorpositionen\n",
    "    if Ort == 'Prinzenpark':\n",
    "        sensorpositionen = [27,27,27,27,27]\n",
    "        return sensorpositionen\n",
    "    if Ort == 'Langer_Kamp':\n",
    "        sensorpositionen = [39.1,39.1,39.1,39.1,39.1]\n",
    "        return sensorpositionen\n",
    "    if Ort == 'Schillstrasse':\n",
    "        sensorpositionen = [38,38,38,38,38]\n",
    "        return sensorpositionen\n",
    "    if Ort == 'Georg_Westermann_Allee':\n",
    "        sensorpositionen = [33,33,33,33,33]\n",
    "        return sensorpositionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9de016be-1e1c-45a6-8305-a04ad3cde5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Hilfsfunktionen.ipynb to script\n",
      "[NbConvertApp] Writing 24885 bytes to Hilfsfunktionen.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Hilfsfunktionen.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903361ea-0229-4ab5-8c1f-a2bd6f2c4651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82835a-338d-4a29-8f0b-4e3966a65ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa7695-9135-40de-a610-081f74573054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e65c68-05e0-42cf-ad9e-93142c473d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09dc469-8d0c-4ea0-9b5c-29f2d55e9aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aabebe-6248-42ad-bbf4-fafe6afc167e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bce07-1bd6-4234-a70b-2b7d1c74be93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
